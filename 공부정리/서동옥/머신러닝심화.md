
# 머신러닝 심화
----
1. **주제**: 머신러닝의 고급 기법
2. **내용**:

- 앙상블(Ensemble):
	- 정의: **여러 개의 개별 모델을 조합**하여 최적의 모델로 **일반화** 하는 방법.
	- 종류
		- 배깅(Bagging):**여러 데이터를 각각 모델에 학습**시킨 다음 투표하거나 평균을 내는 방식
			- 랜덤 포레스트: 여러 결정 트리를 배깅 방식으로 결합하여 예측성능을 높이는 방법
			```python
			from sklearn.ensemble import RandomForestClassifier
			
			# 데이터 준비
			X = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]]
			y = [0, 0, 1, 1, 1]
			
			# 모델 생성 및 학습
			model = RandomForestClassifier()
			model.fit(X, y)
			
			# 예측
			predictions = model.predict([[2, 3]])
			```
		- 보팅(Voting): 하나의 데이터를 여러 모델에 학습 시킨 다음 투표하거나 평균내는 방식
		  ![[스크린샷 2024-07-22 오전 12.07.10.png]]
		- 부스팅 (Adaboost, Gradient Boosting):
		  여러 약한 **학습기를 순차적으로 학습**하여 이전 학습의 오차를 보안하는 방식
			-  그래디언트 부스팅 머신(Gradient Boosting): 
			  순차적으로 학습기를 추가하여 이전 학습기의 오차를 최소화 하는 방향으로 모델을 개선
			```python
			from sklearn.ensemble import GradientBoostingClassifier
			
			# 데이터 준비
			X = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]]
			y = [0, 0, 1, 1, 1]
			
			# 모델 생성 및 학습
			model = GradientBoostingClassifier()
			model.fit(X, y)
			
			# 예측
			predictions = model.predict([[2, 3]])
			```

- **하이퍼파라미터(Hyperparameter)**: 모델 학습 과정에서 설정해야 하는 값
	- 그리드 서치(Grid Search): 모든 하이퍼파라미터 조합을 시도하여 최적의 파라미터를 찾는 방법.
	```python
	from sklearn.model_selection import GridSearchCV
	from sklearn.ensemble import RandomForestClassifier
	
	# 하이퍼파라미터 설정
	param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20, 30]}
	
	# 모델 생성
	model = RandomForestClassifier()
	
	# 그리드 서치
	grid_search = GridSearchCV(model, param_grid, cv=5)
	grid_search.fit(X, y)
	
	best_params = grid_search.best_params_
	```
	- 랜덤 서치(Random Search): 
	  하이퍼파라미터 공간에서 무작위로 샘플링하여 최적의 파라미터를 찾는 방법.
	```python
	from sklearn.model_selection import RandomizedSearchCV
	from sklearn.ensemble import RandomForestClassifier
	from scipy.stats import randint
	
	# 하이퍼파라미터 설정
	param_dist = {'n_estimators': randint(10, 100), 'max_depth': [None, 10, 20, 30]}
	
	# 모델 생성
	model = RandomForestClassifier()
	
	# 랜덤 서치
	random_search = RandomizedSearchCV(model, param_dist, cv=5, n_iter=10, random_state=42)
	random_search.fit(X, y)
	
	best_params = random_search.best_params_
	```

# 비지도학습:

레이블이 없는 데이터에서 패턴을 찾아내는 기법으로 주요 기법으로는 클러스터링과 차원 축소를 사용

- K-평균:
  데이터를 k개의 군집으로 나누는 기법, **중심에 가장 가까운(거리) 포인트들을 선택**하는 군집하 기법
```python
from sklearn.cluster import KMeans

# 데이터 준비
X = [[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]]

# 모델 생성 및 학습
kmeans = KMeans(n_clusters=2)
kmeans.fit(X)

# 예측
predictions = kmeans.predict([[0, 0], [4, 4]])
```
- 주성분 분석 (PCA):
  고차원 데이터를 저차원 공간으로 변환하는 기법. **시각화, 노이즈 감소, 특징 추출 용도**
  1. **데이터 분산을 최대화 하는 방향**으로 새로운 축을 생성
     첫번째 주 성분은 가장 큰 분산을 가지는 방향을 나타내고
   2. 두번째 주성분은 첫번째 주성분에 직교하는 방향,
      두번째로 큰 분산을 가지는 방향을 나타냄.
```python
from sklearn.decomposition import PCA

# 데이터 준비
X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]

# 모델 생성 및 학습
pca = PCA(n_components=2)
X_transformed = pca.fit_transform(X)

```

ex:
	평균 이동(mean shift):
	 **데이터가 모여있는 밀도가 높은 곳**으로 군집의 중심점을 이동하면서 군집화를 수행
	 가우시안 분포 모델(GMM):
	 군집화를 적용하는 데이터가 여러개의 가우시안 분포 모델을 섞어서 생성된 모델로 가정해 수행하는 방식
	 DBSCAN:
	 다차원의 데이터를 밀도 기반으로 서로 가까운 데이터 포인트를 함께 그룹화 수행
	 


이외의 조사:
1. k-최근접 이웃(K-NN):
   새로운 데이터 포인트의 클래스를 유클리드 거리에 따라 가장 가까운 k개의 이웃 데이터 포인트의 클래스 다수결로 결정
   - 목적: 분류 또는 회귀 / K-mean은 군집화
   - 타입: 지도 학습 /K-mean은 비지도학습
2. 모델 평가 방식
	- #### 분류모델 평가
		- **정확도**: 전체 예측에서 맞춘 비율
		- **정밀도**: 양성 예측 중 실제 양성 비율
		- **재현율 또는 민감도**: 실제 양성 중 양성으로 예측한 비율
		- **F1스코어**: 정밀도와 재현율의 조화 평균
		- **Roc곡선**: 모델의 분류 성능을 시각적으로 평가,
		  임계값에서의 True Positive Rate와 False Positive Rate를 나타낸 곡선.
		- **AUC**:ROC 곡선 아래 면적
	- #### 회기 모델 평가
		- **평균 제곱 오차(MSE)**: 예측값과 실제값의 차이의 제곱 평균
		- **평균 절대 오차(MAE)**: 예측값과 실제값의 절대값 평균
		- **R2**: 모델이 데이터를 얼마나 잘 설명하는지의 비율
	- #### 클러스터링 모델 평가
		- **실루엣 스코어**:- 데이터 포인트가 자신이 속한 클러스터 내에 얼마나 잘 맞는지와 다른 클러스터와 얼마나 떨어져 있는지를 평가.
		- **엘보우 방식**:클러스터의 수에 따른 비용 함수(WCSS: Within-Cluster Sum of Squares) 변화를 관찰하여 최적의 클러스터 수를 결정.
	- #### 교차검증
		- **k-겹 교차 검증(K-Fold Cross Validation)**: 
		  데이터를 k개의 폴드로 나누어 k-1개의 폴드로 모델을 훈련시키고 나머지 한 폴드로 검증. 이를 k번 반복하여 평균 성능을 측정
		- %% **층화 교차 검증(Stratified K-Fold CrossValidation)**: - 분류 문제에서 클래스 비율을 유지하면서 데이터를 K개의 폴드로 나누어 교차 검증. %%
3. F 스코어:
   이진 분류 및 정보 검색 시스템의 통계 분석에서 예측 성능의 측정값.
   정밀도와 재현율로 게산 



